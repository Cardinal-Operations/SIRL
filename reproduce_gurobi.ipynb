{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeed8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import subprocess\n",
    "from utils import load_jsonl, extract_code_block, extract_obj, change_variable_types\n",
    "import numpy as np\n",
    "from vllm import LLM, SamplingParams        \n",
    "from transformers import AutoTokenizer                                      \n",
    "from langchain.prompts import PromptTemplate\n",
    "from rule_prompt_utils import gurobi_prompt_temp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoints and tokenizer\n",
    "\n",
    "model_path = '/DATA/disk1/cml/MScache/models/oneday88/SIRL-7B'\n",
    "tensor_parallel_size = 1\n",
    "solver_name = 'gurobi'\n",
    "print(\"Loading model\", model_path)\n",
    "model = LLM(\n",
    "    model=model_path,\n",
    "    tensor_parallel_size=tensor_parallel_size,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "print(\"Model initialized.\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ad7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prompt template and functions for generation\n",
    "zeroshot_prompt_system = PromptTemplate.from_template(gurobi_prompt_temp['system'])\n",
    "zeroshot_prompt_user = PromptTemplate.from_template(gurobi_prompt_temp['user'])\n",
    "def mp_worker(item):\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": zeroshot_prompt_system.format(question=item['en_question']).strip()\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": zeroshot_prompt_user.format(question=item['en_question']).strip()\n",
    "        }\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "    return text\n",
    "\n",
    "def generate_with_model(model, prompt, sampling_params):   \n",
    "    response = model.generate(prompt, sampling_params) \n",
    "    result_text = [g.outputs[0].text for g in response]\n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load decode strategy\n",
    "topk = 1\n",
    "max_tokens = 8192\n",
    "repetition_penalty = 1.02 # To avoid the occasional occurrence of repeated tokens\n",
    "stop_tokens = [\"</s>\"]\n",
    "\n",
    "# top-p strategy\n",
    "sampling_params = SamplingParams(\n",
    "    n=topk,\n",
    "    temperature=0.5,\n",
    "    top_p=0.9,\n",
    "    max_tokens=max_tokens,\n",
    "    stop=stop_tokens,\n",
    "    repetition_penalty=repetition_penalty\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d32cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the pass@1 accuracy\n",
    "def check_result(result_str, item, solver_name='gurobi'):\n",
    "    sub_answer = item['en_answer']\n",
    "    # Convert sub_answer to float or None\n",
    "    sub_answer = None if sub_answer == \"No Best Solution\" or \"-9999\" in str(sub_answer) else float(sub_answer)\n",
    "    \n",
    "    # Extract code snippet\n",
    "    code_snippet = extract_code_block(result_str, solver_name)\n",
    "    if not code_snippet:\n",
    "        return 2\n",
    "    \n",
    "    # Run code snippet\n",
    "    try:\n",
    "        result = subprocess.run(['python3', '-c', code_snippet], capture_output=True, text=True, timeout=100)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return 1 if sub_answer is None else 0\n",
    "    \n",
    "    # Check if execution failed\n",
    "    if result.returncode != 0:\n",
    "        return 3\n",
    "    \n",
    "    # Extract solver result\n",
    "    solver_result = extract_obj(result.stdout,solver_name)\n",
    "    \n",
    "    # check the first time\n",
    "    if solver_result is not None and sub_answer is not None and np.abs(solver_result - sub_answer) / (np.abs(sub_answer) + 1) <= 1e-6:\n",
    "        return 1\n",
    "    # Handle infeasible case or numerical mismatch since we ignore the variable types error\n",
    "    if 'nfeasible' in result.stdout or (solver_result is not None and sub_answer is not None and np.abs(solver_result - sub_answer) / (np.abs(sub_answer) + 1) > 1e-6):\n",
    "        # Try re-running with modified variables: we ignore the variable types error\n",
    "        result_str = change_variable_types(result_str) # change the type of variables\n",
    "        if result_str:\n",
    "            try:\n",
    "                code_snippet = extract_code_block(result_str, solver_name)\n",
    "                result = subprocess.run(['python3', '-c', code_snippet], capture_output=True, text=True, timeout=100)\n",
    "                if result.returncode == 0:\n",
    "                    new_result = extract_obj(result.stdout,solver_name)\n",
    "                    if 'nfeasible' not in result.stdout: # infeasible and Infeasible\n",
    "                        if new_result is not None and sub_answer is not None and np.abs(new_result - sub_answer) / (np.abs(sub_answer) + 1) < 1e-6:\n",
    "                            return 1\n",
    "                        if new_result == sub_answer:\n",
    "                            return 1\n",
    "            except subprocess.TimeoutExpired:\n",
    "                print(\"over_time\")\n",
    "                return 1 if sub_answer is None else 0\n",
    "    \n",
    "    # Handle infeasible case after retry\n",
    "    if 'nfeasible' in result.stdout:\n",
    "        return 1 if sub_answer is None else 0\n",
    "    \n",
    "    # Final comparison\n",
    "    if solver_result is not None and sub_answer is not None:\n",
    "        return 1 if np.abs(solver_result - sub_answer) / (np.abs(sub_answer) + 1) < 1e-6 else 0\n",
    "    return 1 if solver_result == sub_answer else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to check pass@1 accuracy, please run this cell\n",
    "# Test the checkpoint\n",
    "datapath = 'test_data'\n",
    "testdataset = ['NL4OPT.jsonl', 'MAMO_EasyLP.json', 'MAMO_ComplexLP_revised.json', 'IndustryOR_fixed.json', 'OptMATH_Bench_193.jsonl', 'OptMATH_Bench_166.jsonl','OptiBench.jsonl']\n",
    "for filepath in testdataset:\n",
    "    \n",
    "    # loading data\n",
    "    print('Loading data', filepath)\n",
    "    test_data = load_jsonl(os.path.join(datapath, filepath))\n",
    "    print('Finish Loading')\n",
    "    \n",
    "    # generation \n",
    "    \n",
    "    prompt_list = []\n",
    "    for item in test_data:\n",
    "        prompt_list.append(mp_worker(item))\n",
    "    result_strs = generate_with_model(model, prompt_list, sampling_params)\n",
    "    snippet_package_cor = []\n",
    "    score = []\n",
    "    # check the pass@1 accuracy\n",
    "    \n",
    "    for result_str, item in zip(result_strs, test_data):\n",
    "        snippet_package_cor.append(check_result(result_str, item, solver_name))\n",
    "    result = np.bincount(snippet_package_cor)\n",
    "    print(f'Numbers of test cases in dataset {filepath}: {sum(result)}')\n",
    "    print(f'Numbers of pass@1 cases in dataset {filepath}: {result[1]}')\n",
    "    print(f'pass@1 accuracy for dataset {filepath}: {result[1]}/{sum(result)} = {result[1] / sum(result)}')\n",
    "    print('-------------------------------------------------------------------')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to check pass@8 accuracy, please run this cell\n",
    "# Test the checkpoint\n",
    "datapath = 'test_data'\n",
    "testdataset = ['NL4OPT.jsonl', 'MAMO_EasyLP.json', 'MAMO_ComplexLP_revised.json', 'IndustryOR_fixed.json', 'OptMATH_Bench_193.jsonl', 'OptMATH_Bench_166.jsonl','OptiBench.jsonl']\n",
    "for filepath in testdataset:\n",
    "    \n",
    "    # loading data\n",
    "    print('Loading data', filepath)\n",
    "    test_data = [i for i in load_jsonl(os.path.join(datapath, filepath)) for _ in range(8)]\n",
    "    print('Finish Loading')\n",
    "    \n",
    "    # generation \n",
    "    \n",
    "    prompt_list = []\n",
    "    for item in test_data:\n",
    "        prompt_list.append(mp_worker(item))\n",
    "    result_strs = generate_with_model(model, prompt_list, sampling_params)\n",
    "    snippet_package_cor = []\n",
    "    score = []\n",
    "    snippet_package_tmp=[]\n",
    "    # check the pass@8 accuracy\n",
    "    \n",
    "    result_chunks = [result_strs[i:i + 8] for i in range(0, len(result_strs), 8)]\n",
    "    test_data_chunks = [test_data[i:i + 8] for i in range(0, len(test_data), 8)]\n",
    "    for result_chunk, items in zip(result_chunks,test_data_chunks):\n",
    "        for chunk, item in zip(result_chunk, items):\n",
    "            snippet_package_tmp.append(check_result(chunk, item, solver_name))\n",
    "        if 1 in snippet_package_tmp:\n",
    "            snippet_package_cor.append(1)\n",
    "        else:\n",
    "            snippet_package_cor.append(0)\n",
    "        snippet_package_tmp.clear()\n",
    "    result = np.bincount(snippet_package_cor)\n",
    "    print(f'Numbers of test cases in dataset {filepath}: {sum(result)}')\n",
    "    print(f'Numbers of pass@8 cases in dataset {filepath}: {result[1]}')\n",
    "    print(f'pass@8 accuracy for dataset {filepath}: {result[1]}/{sum(result)} = {result[1] / sum(result)}')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
